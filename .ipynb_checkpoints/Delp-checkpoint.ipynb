{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Mihir/Desktop/All_files/Berkeley/Berkeley Fall 2018/IEOR 135/Delp-\r\n"
     ]
    }
   ],
   "source": [
    "!pwd reviews/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"With great hesitation I write this review - this hidden gem in Bernal for me is basically in the same class of restaurants as State Bird or Al's Place (except without the star, which means reservations can actually be made :) ).  But it's inevitable that people will find it eventually...\\n\\nService 4.5/5 - personable and friendly coursing (though they forgot a dish of ours)\\n\\nValue 4/5 - I mean... you'll prob spend $50-70/person + wine $ depending on your appetite, and portion sizes lean small, so you should set your expectations properly.  You're basically getting elevated, 1-Michelin-star equivalent foods so you're not gonna get that for cheap.\\n\\nFood 4.5/5 - special shoutouts to the rich foie on toast, the juicy-tender duck breast, as well as the decadent chocolate cake dessert.  OK - lobster not-actually-ramen noodles, scallops and pork belly (wish the belly was a bit more delicate), the pork loin (wish it was a tad less lean), the crudo (would prefer a more delicate taste), and the well-executed but unmemorable almond cake.\\n\\nFinal score: 4.5/5, rounded up to 5 stars for this lovely li'l spot on the hill!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"/Users/Mihir/Desktop/All_files/Berkeley/Berkeley Fall 2018/IEOR 135/Delp-/reviews/3rd-cousin-san-francisco-2.json\", lines=True)\n",
    "data.iloc[0,:][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# CountVectorizer can actucally handle a lot of the preprocessing for us\n",
    "vectorizer = CountVectorizer(analyzer = \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit([data.iloc[0,:][\"description\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50',\n",
       " '70',\n",
       " 'actually',\n",
       " 'al',\n",
       " 'almond',\n",
       " 'and',\n",
       " 'appetite',\n",
       " 'as',\n",
       " 'basically',\n",
       " 'be',\n",
       " 'belly',\n",
       " 'bernal',\n",
       " 'bird',\n",
       " 'bit',\n",
       " 'breast',\n",
       " 'but',\n",
       " 'cake',\n",
       " 'can',\n",
       " 'cheap',\n",
       " 'chocolate',\n",
       " 'class',\n",
       " 'coursing',\n",
       " 'crudo',\n",
       " 'decadent',\n",
       " 'delicate',\n",
       " 'depending',\n",
       " 'dessert',\n",
       " 'dish',\n",
       " 'duck',\n",
       " 'elevated',\n",
       " 'equivalent',\n",
       " 'eventually',\n",
       " 'except',\n",
       " 'executed',\n",
       " 'expectations',\n",
       " 'final',\n",
       " 'find',\n",
       " 'foie',\n",
       " 'food',\n",
       " 'foods',\n",
       " 'for',\n",
       " 'forgot',\n",
       " 'friendly',\n",
       " 'gem',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gonna',\n",
       " 'great',\n",
       " 'hesitation',\n",
       " 'hidden',\n",
       " 'hill',\n",
       " 'in',\n",
       " 'inevitable',\n",
       " 'is',\n",
       " 'it',\n",
       " 'juicy',\n",
       " 'lean',\n",
       " 'less',\n",
       " 'li',\n",
       " 'll',\n",
       " 'lobster',\n",
       " 'loin',\n",
       " 'lovely',\n",
       " 'made',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'michelin',\n",
       " 'more',\n",
       " 'noodles',\n",
       " 'not',\n",
       " 'of',\n",
       " 'ok',\n",
       " 'on',\n",
       " 'or',\n",
       " 'ours',\n",
       " 'people',\n",
       " 'person',\n",
       " 'personable',\n",
       " 'place',\n",
       " 'pork',\n",
       " 'portion',\n",
       " 'prefer',\n",
       " 'prob',\n",
       " 'properly',\n",
       " 'ramen',\n",
       " 're',\n",
       " 'reservations',\n",
       " 'restaurants',\n",
       " 'review',\n",
       " 'rich',\n",
       " 'rounded',\n",
       " 'same',\n",
       " 'scallops',\n",
       " 'score',\n",
       " 'service',\n",
       " 'set',\n",
       " 'should',\n",
       " 'shoutouts',\n",
       " 'sizes',\n",
       " 'small',\n",
       " 'so',\n",
       " 'special',\n",
       " 'spend',\n",
       " 'spot',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'state',\n",
       " 'tad',\n",
       " 'taste',\n",
       " 'tender',\n",
       " 'that',\n",
       " 'the',\n",
       " 'they',\n",
       " 'this',\n",
       " 'though',\n",
       " 'to',\n",
       " 'toast',\n",
       " 'unmemorable',\n",
       " 'up',\n",
       " 'value',\n",
       " 'was',\n",
       " 'well',\n",
       " 'which',\n",
       " 'will',\n",
       " 'wine',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'without',\n",
       " 'would',\n",
       " 'write',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4 as bs\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def review_cleaner(review):\n",
    "    '''\n",
    "    Clean and preprocess a review.\n",
    "    \n",
    "    1. Remove HTML tags\n",
    "    2. Use regex to remove all special characters (only keep letters)\n",
    "    3. Make strings to lower case and tokenize / word split reviews\n",
    "    4. Remove English stopwords\n",
    "    5. Rejoin to one string\n",
    "    '''\n",
    "    \n",
    "    #1. Remove HTML tags\n",
    "    review = bs.BeautifulSoup(review).text\n",
    "    \n",
    "    #2. Use regex to find emoticons\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
    "    \n",
    "    #3. Remove punctuation\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \",review)\n",
    "    \n",
    "    #4. Tokenize into words (all lower case)\n",
    "    review = review.lower().split()\n",
    "    \n",
    "    #5. Remove stopwords\n",
    "    eng_stopwords = set(stopwords.words(\"english\"))\n",
    "    review = [w for w in review if not w in eng_stopwords]\n",
    "    \n",
    "    #6. Join the review to one sentence\n",
    "    review = ' '.join(review+emoticons)\n",
    "    # add emoticons to the end\n",
    "\n",
    "    return(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mihir/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/Mihir/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'great hesitation write review hidden gem bernal basically class restaurants state bird al place except without star means reservations actually made inevitable people find eventually service personable friendly coursing though forgot dish value mean prob spend person wine depending appetite portion sizes lean small set expectations properly basically getting elevated michelin star equivalent foods gonna get cheap food special shoutouts rich foie toast juicy tender duck breast well decadent chocolate cake dessert ok lobster actually ramen noodles scallops pork belly wish belly bit delicate pork loin wish tad less lean crudo would prefer delicate taste well executed unmemorable almond cake final score rounded stars lovely li l spot hill :)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = review_cleaner(data.iloc[0,:][\"description\"])\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit([first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'al',\n",
       " 'almond',\n",
       " 'appetite',\n",
       " 'basically',\n",
       " 'belly',\n",
       " 'bernal',\n",
       " 'bird',\n",
       " 'bit',\n",
       " 'breast',\n",
       " 'cake',\n",
       " 'cheap',\n",
       " 'chocolate',\n",
       " 'class',\n",
       " 'coursing',\n",
       " 'crudo',\n",
       " 'decadent',\n",
       " 'delicate',\n",
       " 'depending',\n",
       " 'dessert',\n",
       " 'dish',\n",
       " 'duck',\n",
       " 'elevated',\n",
       " 'equivalent',\n",
       " 'eventually',\n",
       " 'except',\n",
       " 'executed',\n",
       " 'expectations',\n",
       " 'final',\n",
       " 'find',\n",
       " 'foie',\n",
       " 'food',\n",
       " 'foods',\n",
       " 'forgot',\n",
       " 'friendly',\n",
       " 'gem',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gonna',\n",
       " 'great',\n",
       " 'hesitation',\n",
       " 'hidden',\n",
       " 'hill',\n",
       " 'inevitable',\n",
       " 'juicy',\n",
       " 'lean',\n",
       " 'less',\n",
       " 'li',\n",
       " 'lobster',\n",
       " 'loin',\n",
       " 'lovely',\n",
       " 'made',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'michelin',\n",
       " 'noodles',\n",
       " 'ok',\n",
       " 'people',\n",
       " 'person',\n",
       " 'personable',\n",
       " 'place',\n",
       " 'pork',\n",
       " 'portion',\n",
       " 'prefer',\n",
       " 'prob',\n",
       " 'properly',\n",
       " 'ramen',\n",
       " 'reservations',\n",
       " 'restaurants',\n",
       " 'review',\n",
       " 'rich',\n",
       " 'rounded',\n",
       " 'scallops',\n",
       " 'score',\n",
       " 'service',\n",
       " 'set',\n",
       " 'shoutouts',\n",
       " 'sizes',\n",
       " 'small',\n",
       " 'special',\n",
       " 'spend',\n",
       " 'spot',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'state',\n",
       " 'tad',\n",
       " 'taste',\n",
       " 'tender',\n",
       " 'though',\n",
       " 'toast',\n",
       " 'unmemorable',\n",
       " 'value',\n",
       " 'well',\n",
       " 'wine',\n",
       " 'wish',\n",
       " 'without',\n",
       " 'would',\n",
       " 'write']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 2, 1, 1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bag = vectorizer.transform(np.array([first]))\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actually</th>\n",
       "      <th>al</th>\n",
       "      <th>almond</th>\n",
       "      <th>appetite</th>\n",
       "      <th>basically</th>\n",
       "      <th>belly</th>\n",
       "      <th>bernal</th>\n",
       "      <th>bird</th>\n",
       "      <th>bit</th>\n",
       "      <th>breast</th>\n",
       "      <th>...</th>\n",
       "      <th>though</th>\n",
       "      <th>toast</th>\n",
       "      <th>unmemorable</th>\n",
       "      <th>value</th>\n",
       "      <th>well</th>\n",
       "      <th>wine</th>\n",
       "      <th>wish</th>\n",
       "      <th>without</th>\n",
       "      <th>would</th>\n",
       "      <th>write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   actually  al  almond  appetite  basically  belly  bernal  bird  bit  \\\n",
       "0         2   1       1         1          2      2       1     1    1   \n",
       "\n",
       "   breast  ...    though  toast  unmemorable  value  well  wine  wish  \\\n",
       "0       1  ...         1      1            1      1     2     1     2   \n",
       "\n",
       "   without  would  write  \n",
       "0        1      1      1  \n",
       "\n",
       "[1 rows x 98 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag.toarray(), columns=vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With great hesitation I write this review - th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Came here to celebrate a surprise birthday and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I came here on the 13th with a party of 4.\\n\\n...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I celebrated my birthday with my family here. ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely delicious.\\n\\nHands down, one of th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  With great hesitation I write this review - th...       5\n",
       "1  Came here to celebrate a surprise birthday and...       5\n",
       "2  I came here on the 13th with a party of 4.\\n\\n...       5\n",
       "3  I celebrated my birthday with my family here. ...       4\n",
       "4  Absolutely delicious.\\n\\nHands down, one of th...       5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating\"] = data[\"reviewRating\"].apply(func = lambda x:x[\"ratingValue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"description\",\"rating\"]]\n",
    "data = data.rename(index=str, columns={\"description\": \"review\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With great hesitation I write this review - th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Came here to celebrate a surprise birthday and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I came here on the 13th with a party of 4.\\n\\n...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I celebrated my birthday with my family here. ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely delicious.\\n\\nHands down, one of th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  With great hesitation I write this review - th...       5\n",
       "1  Came here to celebrate a surprise birthday and...       5\n",
       "2  I came here on the 13th with a party of 4.\\n\\n...       5\n",
       "3  I celebrated my birthday with my family here. ...       4\n",
       "4  Absolutely delicious.\\n\\nHands down, one of th...       5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics # for confusion matrix, accuracy score etc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mihir/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/Mihir/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "num_reviews = len(data['review'])\n",
    "\n",
    "review_clean_original = []\n",
    "\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1)%500 == 0 ):\n",
    "        # print progress\n",
    "        print(\"Done with %d reviews\" %(i+1)) \n",
    "    review_clean_original.append(review_cleaner(data['review'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_clean_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# put everything together in a function\n",
    "\n",
    "def predict_sentiment(cleaned_reviews, y=data[\"rating\"]):\n",
    "\n",
    "    print(\"Creating the bag of words model!\\n\")\n",
    "    # CountVectorizer\" is scikit-learn's bag of words tool, here we show more keywords \n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = None,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = None,   \\\n",
    "                                 max_features = 2000) \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "    cleaned_reviews, y, random_state=0, test_size=.2)\n",
    "\n",
    "    # Then we use fit_transform() to fit the model / learn the vocabulary,\n",
    "    # then transform the data into feature vectors.\n",
    "    # The input should be a list of strings. .toarraty() converts to a numpy array\n",
    "    \n",
    "    train_bag = vectorizer.fit_transform(X_train).toarray()\n",
    "    test_bag = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "    # You can extract the vocabulary created by CountVectorizer\n",
    "    # by running print(vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "    print(\"Training the random forest classifier!\\n\")\n",
    "    # Initialize a Random Forest classifier with 75 trees\n",
    "    forest = RandomForestClassifier(n_estimators = 50) \n",
    "\n",
    "    # Fit the forest to the training set, using the bag of words as \n",
    "    # features and the sentiment labels as the target variable\n",
    "    forest = forest.fit(train_bag, y_train)\n",
    "\n",
    "\n",
    "    train_predictions = forest.predict(train_bag)\n",
    "    test_predictions = forest.predict(test_bag)\n",
    "    \n",
    "    train_acc = metrics.accuracy_score(y_train, train_predictions)\n",
    "    valid_acc = metrics.accuracy_score(y_test, test_predictions)\n",
    "    print(\"The training accuracy is: \", train_acc, \"\\n\", \"The validation accuracy is: \", valid_acc)\n",
    "    \n",
    "    return(forest,vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Reviews\n",
      "Creating the bag of words model!\n",
      "\n",
      "Training the random forest classifier!\n",
      "\n",
      "The training accuracy is:  1.0 \n",
      " The validation accuracy is:  0.589743589744\n"
     ]
    }
   ],
   "source": [
    "print('Original Reviews')\n",
    "forest1,vec1 = predict_sentiment(review_clean_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
